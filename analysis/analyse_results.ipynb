{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Neurocomputing/ESANN 2024\n",
    "\n",
    "This notebook contains the code to analyse the results of the \n",
    "Neurocomputing/ESANN 2024 paper, and it is responsible for generating\n",
    "the figures and tables in the paper.\n",
    "\n",
    "The notebook is organised as follows:\n",
    "\n",
    "1. The first section contains imports, constants, helper functions and load the \n",
    "    data.\n",
    "\n",
    "2. We show that the dict-wisard has competitive performance with the \n",
    "    classical machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General constants, hhelper functions, and data loading\n",
    "\n",
    "Imports, global constants and packages' configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "from utils import write_figure, write_latex_table, aggregate_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)\n",
    "\n",
    "# ---------- Paths -------------\n",
    "# -- Inputs\n",
    "datasets_info_path = Path(\"datasets_info.json\")\n",
    "results_path = Path(\"results_wisard_folded.csv\")\n",
    "results_sklearn_path = Path(\"results_sklearn_folded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read inputs and create a full dataframe\n",
    "\n",
    "1. Read the datasets specifications (`dataset_info`)\n",
    "2. Read the wisard results (`wisard_results`)\n",
    "3. Read the sklearn results (`sklearn_results`)\n",
    "4. Create a results dataframe, mergind dataset_info, wisard_results and sklearn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>size</th>\n",
       "      <th>features</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>balanced</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>141416</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>398</td>\n",
       "      <td>171</td>\n",
       "      <td>False</td>\n",
       "      <td>f1 weighted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dry_bean</td>\n",
       "      <td>1773910</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>10888</td>\n",
       "      <td>2723</td>\n",
       "      <td>False</td>\n",
       "      <td>f1 weighted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glass</td>\n",
       "      <td>17413</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>149</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>f1 weighted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_name     size  features  num_classes  train_size  test_size  \\\n",
       "0  breast_cancer   141416        30            3         398        171   \n",
       "1       dry_bean  1773910        16            7       10888       2723   \n",
       "2          glass    17413         9           24         149         65   \n",
       "\n",
       "   balanced       metric  \n",
       "0     False  f1 weighted  \n",
       "1     False  f1 weighted  \n",
       "2     False  f1 weighted  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasets information\n",
    "datasets_info = pd.read_json(datasets_info_path, orient=\"index\").reset_index(drop=True)\n",
    "datasets_info.rename(columns={\"name\": \"dataset_name\"}, inplace=True)\n",
    "datasets_info.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table written to: tables/datasets_info.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2852505/3004690570.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info.loc[:, \"size\"] = info[\"size\"] / 1024\n",
      "/tmp/ipykernel_2852505/3004690570.py:16: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_str = info.to_latex(\n"
     ]
    }
   ],
   "source": [
    "info = datasets_info[\n",
    "    [\"dataset_name\", \"features\", \"size\", \"num_classes\", \"balanced\"]\n",
    "]\n",
    "info.loc[:, \"size\"] = info[\"size\"] / 1024\n",
    "\n",
    "info = info.rename(\n",
    "    columns={\n",
    "        \"dataset_name\": \"Dataset\",\n",
    "        \"features\": \"Features\",\n",
    "        \"size\": \"Size (KB)\",\n",
    "        \"num_classes\": \"Classes\",\n",
    "        \"balanced\": \"Is Balanced?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "latex_str = info.to_latex(\n",
    "    index=False,\n",
    "    escape=True,\n",
    "    caption=\"Datasets information\",\n",
    "    label=\"tab:datasets_info\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "write_latex_table(\"datasets_info.tex\", latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wisard results\n",
    "\n",
    "Read and parse wisard result to `wisard_results` dataframe.\n",
    "\n",
    "**Note**: The `wisard_results` already has aggregated results for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>fold</th>\n",
       "      <th>model</th>\n",
       "      <th>config_name</th>\n",
       "      <th>tuple_size</th>\n",
       "      <th>encoder</th>\n",
       "      <th>resolution</th>\n",
       "      <th>bleach</th>\n",
       "      <th>rams per discriminator</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "      <th>ties</th>\n",
       "      <th>ties_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11970</th>\n",
       "      <td>wine</td>\n",
       "      <td>1</td>\n",
       "      <td>Wisard</td>\n",
       "      <td>StreamThreshold (W: 16.0, D: 1.0, T: 145.0)</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>thermometer</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3120.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.8165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>segment</td>\n",
       "      <td>1</td>\n",
       "      <td>Wisard</td>\n",
       "      <td>HeavyHitters (NR: 995.0, W: 73.0, D: 3.0)</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>distributive-thermometer</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>237272.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>94.0000</td>\n",
       "      <td>5.6569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset  fold   model                                  config_name  \\\n",
       "11970     wine     1  Wisard  StreamThreshold (W: 16.0, D: 1.0, T: 145.0)   \n",
       "10246  segment     1  Wisard    HeavyHitters (NR: 995.0, W: 73.0, D: 3.0)   \n",
       "\n",
       "       tuple_size                   encoder  resolution  bleach  \\\n",
       "11970     20.0000               thermometer          20      12   \n",
       "10246     32.0000  distributive-thermometer          64       9   \n",
       "\n",
       "       rams per discriminator  accuracy  accuracy_std     f1  f1_std  \\\n",
       "11970                      13    0.7222        0.0000 0.6102  0.0000   \n",
       "10246                      38    0.8550        0.0077 0.8451  0.0115   \n",
       "\n",
       "       model_size  model_size_std    ties  ties_std  \n",
       "11970   3120.0000          0.0000 13.0000    0.8165  \n",
       "10246 237272.0000          0.0000 94.0000    5.6569  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_wisard_config_name(row) -> str:\n",
    "    \"\"\"Given a row, parse the name of configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        The row of the dataframe.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The name of the configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    names = []\n",
    "    if not pd.isna(row[\"num_hitters\"]):\n",
    "        names.append(f\"NR: {row['num_hitters']}\")\n",
    "    if not pd.isna(row[\"width\"]):\n",
    "        names.append(f\"W: {row['width']}\")\n",
    "    if not pd.isna(row[\"depth\"]):\n",
    "        names.append(f\"D: {row['depth']}\")\n",
    "    if not pd.isna(row[\"capacity\"]):\n",
    "        names.append(f\"C: {row['capacity']}\")\n",
    "    if not pd.isna(row[\"bucket_size\"]):\n",
    "        names.append(f\"BS: {row['bucket_size']}\")\n",
    "    if not pd.isna(row[\"threshold\"]):\n",
    "        names.append(f\"T: {row['threshold']}\")\n",
    "    if not pd.isna(row[\"est_elements\"]):\n",
    "        names.append(f\"EST: {row['est_elements']}\")\n",
    "    if not pd.isna(row[\"false_positive_rate\"]):\n",
    "        names.append(f\"FPR: {row['false_positive_rate']}\")\n",
    "\n",
    "    if names:\n",
    "        names = \", \".join(names)\n",
    "        return f\"{row['ram']} ({names})\"\n",
    "    else:\n",
    "        return row[\"ram\"]\n",
    "\n",
    "\n",
    "# --- Read results and add a column with the name of the configuration ---\n",
    "wisard_results = pd.read_csv(results_path).drop_duplicates()\n",
    "\n",
    "# --- Add useful columns ---\n",
    "wisard_results[\"tuple_size\"] = (\n",
    "    wisard_results[\"resolution\"] / wisard_results[\"tuple_resolution_factor\"]\n",
    ")\n",
    "wisard_results[\"config_name\"] = wisard_results.apply(\n",
    "    parse_wisard_config_name, axis=1\n",
    ")\n",
    "\n",
    "# --- Select the columns of interest ---\n",
    "wisard_results = wisard_results[\n",
    "    [\n",
    "        \"dataset_name\",\n",
    "        \"config_name\",\n",
    "        \"test_accuracy_mean\",\n",
    "        \"test_accuracy_std\",\n",
    "        \"test_f1 weighted_mean\",\n",
    "        \"test_f1 weighted_std\",\n",
    "        \"test_model size_mean\",\n",
    "        \"test_model size_std\",\n",
    "        \"test_ties_mean\",\n",
    "        \"test_ties_std\",\n",
    "        \"tuple_size\",\n",
    "        \"encoder\",\n",
    "        \"resolution\",\n",
    "        \"bleach\",\n",
    "        \"rams per discriminator\",\n",
    "        \"ram\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# --- Rename columns ---\n",
    "wisard_results = wisard_results.rename(\n",
    "    columns={\n",
    "        \"dataset_name\": \"dataset\",\n",
    "        \"ram\": \"model\",\n",
    "        \"test_ties_mean\": \"ties\",\n",
    "        \"test_ties_std\": \"ties_std\",\n",
    "        \"test_accuracy_mean\": \"accuracy\",\n",
    "        \"test_accuracy_std\": \"accuracy_std\",\n",
    "        \"test_f1 weighted_mean\": \"f1\",\n",
    "        \"test_f1 weighted_std\": \"f1_std\",\n",
    "        \"test_model size_mean\": \"model_size\",\n",
    "        \"test_model size_std\": \"model_size_std\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- Add model column and drop duplicates ---\n",
    "wisard_results[\"model\"] = \"Wisard\"\n",
    "wisard_results.drop_duplicates(inplace=True)\n",
    "\n",
    "# Split dataset name from fold\n",
    "wisard_results[[\"dataset\", \"fold\"]] = wisard_results[\"dataset\"].str.split(\n",
    "    \"_fold_\", expand=True\n",
    ")\n",
    "wisard_results[\"fold\"] = wisard_results[\"fold\"].astype(int)\n",
    "\n",
    "\n",
    "# Rearange columns\n",
    "wisard_results = wisard_results[[\n",
    "    \"dataset\",\n",
    "    \"fold\",\n",
    "    \"model\",\n",
    "    \"config_name\",\n",
    "    \"tuple_size\",\n",
    "    \"encoder\",\n",
    "    \"resolution\",\n",
    "    \"bleach\",\n",
    "    \"rams per discriminator\",\n",
    "    \"accuracy\",\n",
    "    \"accuracy_std\",\n",
    "    \"f1\",\n",
    "    \"f1_std\",\n",
    "    \"model_size\",\n",
    "    \"model_size_std\",\n",
    "    \"ties\",\n",
    "    \"ties_std\",\n",
    "]]\n",
    "\n",
    "wisard_results.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>61675.6667</td>\n",
       "      <td>64519.6794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dry_bean</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>968603.5333</td>\n",
       "      <td>443718.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glass</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>53000.8667</td>\n",
       "      <td>22996.4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_segmentation</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.8526</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>142505.2000</td>\n",
       "      <td>46475.5446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iris</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>2949.1333</td>\n",
       "      <td>3307.9763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>letter</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>7193661.8667</td>\n",
       "      <td>4057207.8151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motion_sense</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>52461826.4000</td>\n",
       "      <td>14175681.6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>optical_handwritten</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>11184680.4667</td>\n",
       "      <td>13594443.0243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rice</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>46699.2000</td>\n",
       "      <td>29841.7810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>satimage</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>6291516.6000</td>\n",
       "      <td>4400154.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>segment</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>131163.3333</td>\n",
       "      <td>34125.9199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sepsis</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7660.2000</td>\n",
       "      <td>5440.5641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>372700.8667</td>\n",
       "      <td>221038.1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wine</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>97341.2667</td>\n",
       "      <td>56457.3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yeast</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>727397.8000</td>\n",
       "      <td>226269.2917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset        model  accuracy  accuracy_std     f1  f1_std  \\\n",
       "0         breast_cancer  Dict-Wisard    0.9537        0.0179 0.9537  0.0177   \n",
       "1              dry_bean  Dict-Wisard    0.9027        0.0040 0.9028  0.0035   \n",
       "2                 glass  Dict-Wisard    0.6842        0.0509 0.6333  0.0481   \n",
       "3    image_segmentation  Dict-Wisard    0.8556        0.0181 0.8526  0.0223   \n",
       "4                  iris  Dict-Wisard    0.9800        0.0277 0.9800  0.0277   \n",
       "5                letter  Dict-Wisard    0.8739        0.0291 0.8751  0.0286   \n",
       "6          motion_sense  Dict-Wisard    0.7380        0.0324 0.7261  0.0329   \n",
       "7   optical_handwritten  Dict-Wisard    0.9715        0.0082 0.9715  0.0082   \n",
       "8                  rice  Dict-Wisard    0.9178        0.0145 0.9176  0.0146   \n",
       "9              satimage  Dict-Wisard    0.8904        0.0052 0.8864  0.0058   \n",
       "10              segment  Dict-Wisard    0.8730        0.0140 0.8653  0.0186   \n",
       "11               sepsis  Dict-Wisard    0.9263        0.0000 0.8909  0.0000   \n",
       "12              vehicle  Dict-Wisard    0.8850        0.0195 0.8836  0.0197   \n",
       "13                 wine  Dict-Wisard    0.9603        0.0320 0.9601  0.0323   \n",
       "14                yeast  Dict-Wisard    0.5589        0.0077 0.5447  0.0046   \n",
       "\n",
       "      model_size  model_size_std  \n",
       "0     61675.6667      64519.6794  \n",
       "1    968603.5333     443718.5251  \n",
       "2     53000.8667      22996.4997  \n",
       "3    142505.2000      46475.5446  \n",
       "4      2949.1333       3307.9763  \n",
       "5   7193661.8667    4057207.8151  \n",
       "6  52461826.4000   14175681.6535  \n",
       "7  11184680.4667   13594443.0243  \n",
       "8     46699.2000      29841.7810  \n",
       "9   6291516.6000    4400154.0757  \n",
       "10   131163.3333      34125.9199  \n",
       "11     7660.2000       5440.5641  \n",
       "12   372700.8667     221038.1812  \n",
       "13    97341.2667      56457.3154  \n",
       "14   727397.8000     226269.2917  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wisard_results = wisard_results[(wisard_results[\"config_name\"] == \"Dict\")]\n",
    "\n",
    "lines = []\n",
    "for (dataset, fold), dataset_df in dict_wisard_results.groupby([\"dataset\", \"fold\"]):\n",
    "    metric_name = datasets_info.loc[datasets_info[\"dataset_name\"] == dataset, \"metric\"].iloc[0]\n",
    "    if metric_name == \"f1 weighted\":\n",
    "        metric_name = \"f1\"\n",
    "    line = dataset_df.sort_values(by=metric_name, ascending=False).iloc[0]\n",
    "    lines.append(line)\n",
    "\n",
    "dict_wisard_results = pd.DataFrame(lines)\n",
    "\n",
    "dict_wisard_results = aggregate_mean_std(\n",
    "    dict_wisard_results, \n",
    "    group_by=[\"dataset\"],\n",
    "    keys_to_aggregate=[\"accuracy\", \"f1\", \"model_size\"]\n",
    ")\n",
    "\n",
    "dict_wisard_results[\"model\"] = \"Dict-Wisard\"\n",
    "\n",
    "# Rearange columns\n",
    "dict_wisard_results = dict_wisard_results[[\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"accuracy_std\",\n",
    "    \"f1\",\n",
    "    \"f1_std\",\n",
    "    \"model_size\",\n",
    "    \"model_size_std\",\n",
    "]]\n",
    "\n",
    "dict_wisard_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn results\n",
    "\n",
    "Read and parse sklearn result to `sklearn_results` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yeast</td>\n",
       "      <td>KNN-10</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>182341.8000</td>\n",
       "      <td>64.3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>iris</td>\n",
       "      <td>MLP-1L</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>27602.5333</td>\n",
       "      <td>0.5055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset   model  accuracy  accuracy_std     f1  f1_std  model_size  \\\n",
       "14   yeast  KNN-10    0.5020        0.0866 0.4983  0.0748 182341.8000   \n",
       "34    iris  MLP-1L    0.9800        0.0298 0.9798  0.0301  27602.5333   \n",
       "\n",
       "    model_size_std  \n",
       "14         64.3988  \n",
       "34          0.5055  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sklearn results and aggregate multiple runs\n",
    "sklearn_results = pd.read_csv(results_sklearn_path).drop_duplicates()\n",
    "\n",
    "# Aggregate metric for multiple runs\n",
    "sklearn_results = aggregate_mean_std(\n",
    "    df=sklearn_results,\n",
    "    group_by=[\n",
    "        \"model\",\n",
    "        \"model kwargs\",\n",
    "        \"dataset name\",\n",
    "        \"experiment name\",\n",
    "    ],\n",
    "    keys_to_aggregate=[\n",
    "        \"accuracy\",\n",
    "        \"f1 weighted\",\n",
    "        \"f1 macro\",\n",
    "        \"f1 micro\",\n",
    "        \"train time\",\n",
    "        \"predict time\",\n",
    "        \"model size\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Select columns of interest\n",
    "sklearn_results = sklearn_results[\n",
    "    [\n",
    "        \"dataset name\",\n",
    "        \"model\",\n",
    "        \"model kwargs\",\n",
    "        \"accuracy\",\n",
    "        \"accuracy_std\",\n",
    "        \"f1 weighted\",\n",
    "        \"f1 weighted_std\",\n",
    "        \"model size\",\n",
    "        \"model size_std\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Rename columns\n",
    "sklearn_results.rename(\n",
    "    columns={\n",
    "        \"dataset name\": \"dataset\",\n",
    "        \"model kwargs\": \"config_name\",\n",
    "        \"f1 weighted\": \"f1\",\n",
    "        \"f1 weighted_std\": \"f1_std\",\n",
    "        \"model size\": \"model_size\",\n",
    "        \"model size_std\": \"model_size_std\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "def transform_config_to_model_name(row):\n",
    "    config = json.loads(row[\"config_name\"])\n",
    "    if row[\"model\"] == \"knn\":\n",
    "        row[\"model\"] = f\"KNN-{config['n_neighbors']}\"\n",
    "    elif row[\"model\"] == \"mlp\":\n",
    "        row[\"model\"] = f\"MLP-{len(config['hidden_layer_sizes'])}L\"\n",
    "    elif row[\"model\"] == \"random-forest\":\n",
    "        row[\"model\"] = \"Random Forest\"\n",
    "    elif row[\"model\"] == \"svm\":\n",
    "        row[\"model\"] = f\"SVM-{config.get('kernel', 'rbf')}\"\n",
    "        \n",
    "    row = row.drop(\"config_name\")\n",
    "    return row\n",
    "        \n",
    "\n",
    "# Transform config to model name\n",
    "sklearn_results = sklearn_results.apply(transform_config_to_model_name, axis=1)\n",
    "\n",
    "# Split dataset name from fold\n",
    "sklearn_results[['dataset', 'fold']] = sklearn_results['dataset'].str.split('_fold_', expand=True)\n",
    "sklearn_results['fold'] = sklearn_results['fold'].astype(int)\n",
    "\n",
    "# Aggregate folds\n",
    "n_folds = sklearn_results[\"fold\"].nunique()\n",
    "old_len = len(sklearn_results)\n",
    "\n",
    "sklearn_results = aggregate_mean_std(\n",
    "    df=sklearn_results,\n",
    "    group_by=[\"model\", \"dataset\"],\n",
    "    keys_to_aggregate=[\"accuracy\", \"f1\", \"model_size\"]\n",
    ")\n",
    "\n",
    "# Check if the aggregation was correct\n",
    "assert len(sklearn_results) == old_len / n_folds, f\"Expected {old_len / n_folds} got {len(sklearn_results)}\"\n",
    "\n",
    "# Rearange columns\n",
    "sklearn_results = sklearn_results[[\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"accuracy\",\n",
    "    \"accuracy_std\",\n",
    "    \"f1\",\n",
    "    \"f1_std\",\n",
    "    \"model_size\",\n",
    "    \"model_size_std\",\n",
    "]]\n",
    "\n",
    "sklearn_results.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>iris</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>159934.4667</td>\n",
       "      <td>13085.7338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>image_segmentation</td>\n",
       "      <td>MLP-1L</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>73339.4000</td>\n",
       "      <td>0.5477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>MLP-3L</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>567566.0000</td>\n",
       "      <td>260.4160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset          model  accuracy  accuracy_std     f1  f1_std  \\\n",
       "42                iris  Random Forest    0.9467        0.0506 0.9465  0.0506   \n",
       "30  image_segmentation         MLP-1L    0.6429        0.2614 0.6391  0.2608   \n",
       "5        breast_cancer         MLP-3L    0.9087        0.0396 0.9082  0.0406   \n",
       "\n",
       "    model_size  model_size_std  \n",
       "42 159934.4667      13085.7338  \n",
       "30  73339.4000          0.5477  \n",
       "5  567566.0000        260.4160  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge results\n",
    "results_df = pd.concat([dict_wisard_results, sklearn_results])\n",
    "results_df = results_df.sort_values(by=[\"dataset\", \"model\"]).reset_index(drop=True)\n",
    "results_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "# Add metric column based on dataset info\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for _, row in datasets_info.iterrows():\n",
    "    df = results_df[results_df[\"dataset\"] == row[\"dataset_name\"]].copy()\n",
    "    if row[\"metric\"] == \"f1 weighted\":\n",
    "        metric = \"f1\"\n",
    "        metric_std = \"f1_std\"\n",
    "    else:\n",
    "        metric = \"accuracy\"\n",
    "        metric_std = \"accuracy_std\"\n",
    "    \n",
    "    df[\"metric\"] = df[metric]\n",
    "    df[\"metric_std\"] = df[metric_std]\n",
    "    df[\"performance_metric\"] = metric\n",
    "    dfs.append(df.reset_index(drop=True))\n",
    "\n",
    "results_df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# Some beautify\n",
    "results_df.dataset = results_df.dataset.str.replace(\"_\", \" \")\n",
    "results_df.dataset = results_df.dataset.str.title()\n",
    "results_df\n",
    "\n",
    "results_df.to_csv(\"results.csv\", index=False)\n",
    "print(\"Results saved to results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative performance (per dataset, normalized by model with best metric value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results_relative.csv\n"
     ]
    }
   ],
   "source": [
    "relative_results_df = results_df.copy()\n",
    "\n",
    "\n",
    "for dset, df in relative_results_df.groupby(\"dataset\"):\n",
    "    highest_metric = df[\"metric\"].idxmax()\n",
    "    \n",
    "    for metric in [\"accuracy\", \"f1\", \"model_size\", \"metric\"]:\n",
    "        relative_results_df.loc[df.index, f\"{metric}_relative\"] = df[metric] / df.loc[highest_metric, metric]\n",
    "        \n",
    "relative_results_df.to_csv(\"results_relative.csv\", index=False)\n",
    "print(\"Results saved to results_relative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_std</th>\n",
       "      <th>performance_metric</th>\n",
       "      <th>accuracy_relative</th>\n",
       "      <th>f1_relative</th>\n",
       "      <th>model_size_relative</th>\n",
       "      <th>metric_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Image Segmentation</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.2938</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>517000.6000</td>\n",
       "      <td>25632.6888</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.2938</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.8516</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>3.6279</td>\n",
       "      <td>0.8516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Segment</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>131163.3333</td>\n",
       "      <td>34125.9199</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.8883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Dict-Wisard</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>61675.6667</td>\n",
       "      <td>64519.6794</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.9898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset          model  accuracy  accuracy_std     f1  f1_std  \\\n",
       "33  Image Segmentation  Random Forest    0.7286        0.2938 0.7228  0.3005   \n",
       "90             Segment    Dict-Wisard    0.8730        0.0140 0.8653  0.0186   \n",
       "0        Breast Cancer    Dict-Wisard    0.9537        0.0179 0.9537  0.0177   \n",
       "\n",
       "    model_size  model_size_std  metric  metric_std performance_metric  \\\n",
       "33 517000.6000      25632.6888  0.7286      0.2938           accuracy   \n",
       "90 131163.3333      34125.9199  0.8730      0.0140           accuracy   \n",
       "0   61675.6667      64519.6794  0.9537      0.0177                 f1   \n",
       "\n",
       "    accuracy_relative  f1_relative  model_size_relative  metric_relative  \n",
       "33             0.8516       0.8479               3.6279           0.8516  \n",
       "90             0.8883       0.8804               0.0648           0.8883  \n",
       "0              0.9896       0.9898               0.1969           0.9898  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_results_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wisard is competitive with classical machine learning algorithms\n",
    "\n",
    "### Size and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_line(df):\n",
    "    line = {\"dataset\": \"Mean\"}\n",
    "    for c in df.columns:\n",
    "        if c != \"dataset\":\n",
    "            line[c] = df[c].mean()\n",
    "    df.loc[len(df)] = line\n",
    "    return df\n",
    "\n",
    "def raw_relative_table(df, raw_metric, relative_metric, order_of_models: List[str]):\n",
    "    # Pivot the DataFrame to create the raw metric table and relative table\n",
    "    raw_df = (\n",
    "        df.pivot(index=\"dataset\", columns=\"model\", values=raw_metric)\n",
    "        .rename_axis(None, axis=1)\n",
    "        .reset_index()\n",
    "    )\n",
    "    raw_df = raw_df[[\"dataset\"] + order_of_models]\n",
    "    raw_df = add_mean_line(raw_df)\n",
    "    raw_df.set_index(\"dataset\", inplace=True)\n",
    "\n",
    "    relative_df = (\n",
    "        df.pivot(\n",
    "            index=\"dataset\", columns=\"model\", values=relative_metric\n",
    "        )\n",
    "        .rename_axis(None, axis=1)\n",
    "        .reset_index()\n",
    "    )\n",
    "    relative_df = relative_df[[\"dataset\"] + order_of_models]\n",
    "    relative_df = add_mean_line(relative_df)\n",
    "    relative_df.set_index(\"dataset\", inplace=True)\n",
    "    \n",
    "    # Concatenating the DataFrames\n",
    "    final_df = pd.concat([raw_df, relative_df], axis=1)\n",
    "\n",
    "    final_df.columns = pd.MultiIndex.from_product(\n",
    "        [[\"Absolute\", \"Relative\"], raw_df.columns.str.split(\"_\").str[0]]\n",
    "    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table written to: tables/performance_table.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2852505/3234757927.py:22: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  write_latex_table(\"performance_table.tex\", performance_df.to_latex(float_format=\"%.2f\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Absolute</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Relative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Wisard</th>\n",
       "      <th>RF</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP-1L</th>\n",
       "      <th>MLP-2L</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Wisard</th>\n",
       "      <th>RF</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP-1L</th>\n",
       "      <th>MLP-2L</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dry Bean</th>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.9501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Segmentation</th>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>0.3987</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>0.5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris</th>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>0.4029</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.5161</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rice</th>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8516</td>\n",
       "      <td>0.7013</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.6735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sepsis</th>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yeast</th>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9072</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breast Cancer</th>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.8455</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical Handwritten</th>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wine</th>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>0.7361</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.3829</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.4173</td>\n",
       "      <td>0.8022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satimage</th>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle</th>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.8761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letter</th>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Segment</th>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.8428</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Sense</th>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.6423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glass</th>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.8130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Absolute                                    Relative  \\\n",
       "                      Wisard     RF    KNN MLP-1L MLP-2L    SVM   Wisard   \n",
       "Dry Bean              0.9537 0.9635 0.9308 0.9245 0.9037 0.9155   0.9898   \n",
       "Image Segmentation    0.9028 0.8322 0.6526 0.3599 0.3804 0.5391   1.0000   \n",
       "Iris                  0.6333 0.7807 0.6070 0.4029 0.4016 0.1862   0.8113   \n",
       "Rice                  0.8556 0.7286 0.6000 0.6429 0.6397 0.5762   1.0000   \n",
       "Sepsis                0.9800 0.9467 0.9467 0.9800 0.9800 0.9533   1.0000   \n",
       "Yeast                 0.8739 0.9633 0.9519 0.9245 0.9536 0.9267   0.9072   \n",
       "Breast Cancer         0.7380 0.8995 0.7706 0.8455 0.8478 0.7537   0.8205   \n",
       "Optical Handwritten   0.9715 0.9832 0.9872 0.9829 0.9841 0.9886   0.9825   \n",
       "Wine                  0.9176 0.7589 0.7361 0.4540 0.3829 0.7360   1.0000   \n",
       "Satimage              0.8864 0.9137 0.9082 0.9100 0.9112 0.8956   0.9701   \n",
       "Vehicle               0.8730 0.9828 0.9420 0.9535 0.9466 0.8610   0.8883   \n",
       "Letter                0.8909 0.8909 0.8906 0.8909 0.8909 0.8909   1.0000   \n",
       "Segment               0.8850 0.9594 0.8428 0.8098 0.8298 0.6820   0.9224   \n",
       "Motion Sense          0.9601 0.9829 0.6966 0.7311 0.6156 0.6313   0.9767   \n",
       "Glass                 0.5447 0.5329 0.4818 0.4996 0.5114 0.5186   1.0000   \n",
       "Mean                  0.8578 0.8746 0.7963 0.7541 0.7453 0.7370   0.9512   \n",
       "\n",
       "                                                        \n",
       "                        RF    KNN MLP-1L MLP-2L    SVM  \n",
       "Dry Bean            1.0000 0.9660 0.9595 0.9379 0.9501  \n",
       "Image Segmentation  0.9218 0.7229 0.3987 0.4213 0.5971  \n",
       "Iris                1.0000 0.7775 0.5161 0.5144 0.2385  \n",
       "Rice                0.8516 0.7013 0.7514 0.7477 0.6735  \n",
       "Sepsis              0.9660 0.9660 1.0000 1.0000 0.9728  \n",
       "Yeast               1.0000 0.9882 0.9597 0.9899 0.9620  \n",
       "Breast Cancer       1.0000 0.8567 0.9400 0.9425 0.8379  \n",
       "Optical Handwritten 0.9943 0.9984 0.9940 0.9953 0.9998  \n",
       "Wine                0.8271 0.8023 0.4948 0.4173 0.8022  \n",
       "Satimage            1.0000 0.9940 0.9960 0.9973 0.9802  \n",
       "Vehicle             1.0000 0.9584 0.9702 0.9631 0.8761  \n",
       "Letter              0.9999 0.9996 1.0000 1.0000 1.0000  \n",
       "Segment             1.0000 0.8785 0.8440 0.8649 0.7109  \n",
       "Motion Sense        1.0000 0.7088 0.7438 0.6263 0.6423  \n",
       "Glass               0.9783 0.8845 0.9172 0.9389 0.9520  \n",
       "Mean                0.9693 0.8802 0.8323 0.8238 0.8130  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results_relative.csv\")\n",
    "df = df[~df[\"model\"].isin([\"KNN-10\", \"MLP-3L\", \"SVM-poly\"])]\n",
    "df.loc[df[\"model\"] == \"KNN-5\", \"model\"] = \"KNN\"\n",
    "df.loc[df[\"model\"] == \"SVM-rbf\", \"model\"] = \"SVM\"\n",
    "df.loc[df[\"model\"] == \"Random Forest\", \"model\"] = \"RF\"\n",
    "df.loc[df[\"model\"] == \"Dict-Wisard\", \"model\"] = \"Wisard\"\n",
    "\n",
    "order_of_models = [\n",
    "    \"Wisard\",\n",
    "    \"RF\",\n",
    "    \"KNN\",\n",
    "    \"MLP-1L\",\n",
    "    \"MLP-2L\",\n",
    "    \"SVM\"\n",
    "]\n",
    "\n",
    "performance_df = raw_relative_table(df, \"metric\", \"metric_relative\", order_of_models)\n",
    "order_of_datasets = performance_df[\"Relative\"][\"Wisard\"].sort_values(ascending=False).keys().to_list()\n",
    "order_of_datasets.remove(\"Mean\")\n",
    "order_of_datasets.append(\"Mean\")\n",
    "performance_df.index = order_of_datasets\n",
    "write_latex_table(\"performance_table.tex\", performance_df.to_latex(float_format=\"%.2f\"))\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table written to: tables/size_table.tex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2852505/1570870317.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  write_latex_table(\"size_table.tex\", size_df.to_latex(float_format=\"%.2f\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Absolute</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Relative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Wisard</th>\n",
       "      <th>RF</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP-1L</th>\n",
       "      <th>MLP-2L</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Wisard</th>\n",
       "      <th>RF</th>\n",
       "      <th>KNN</th>\n",
       "      <th>MLP-1L</th>\n",
       "      <th>MLP-2L</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dry Bean</th>\n",
       "      <td>60.2301</td>\n",
       "      <td>305.8702</td>\n",
       "      <td>110.9039</td>\n",
       "      <td>81.8907</td>\n",
       "      <td>317.5171</td>\n",
       "      <td>32.1240</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>1.0381</td>\n",
       "      <td>0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Segmentation</th>\n",
       "      <td>945.9019</td>\n",
       "      <td>14015.5705</td>\n",
       "      <td>1446.8768</td>\n",
       "      <td>62.0370</td>\n",
       "      <td>299.4306</td>\n",
       "      <td>1466.3193</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>14.8172</td>\n",
       "      <td>1.5296</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.3166</td>\n",
       "      <td>1.5502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris</th>\n",
       "      <td>51.7587</td>\n",
       "      <td>781.1236</td>\n",
       "      <td>29.1660</td>\n",
       "      <td>44.5428</td>\n",
       "      <td>282.0652</td>\n",
       "      <td>20.8877</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rice</th>\n",
       "      <td>139.1652</td>\n",
       "      <td>504.8834</td>\n",
       "      <td>26.9375</td>\n",
       "      <td>71.6205</td>\n",
       "      <td>308.5584</td>\n",
       "      <td>29.1854</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.6279</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0.5146</td>\n",
       "      <td>2.2172</td>\n",
       "      <td>0.2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sepsis</th>\n",
       "      <td>2.8800</td>\n",
       "      <td>156.1860</td>\n",
       "      <td>10.8428</td>\n",
       "      <td>26.9556</td>\n",
       "      <td>263.9021</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>54.2310</td>\n",
       "      <td>3.7648</td>\n",
       "      <td>9.3595</td>\n",
       "      <td>91.6323</td>\n",
       "      <td>1.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yeast</th>\n",
       "      <td>7025.0604</td>\n",
       "      <td>111966.4944</td>\n",
       "      <td>2125.8564</td>\n",
       "      <td>109.7174</td>\n",
       "      <td>346.6115</td>\n",
       "      <td>2958.7748</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breast Cancer</th>\n",
       "      <td>51232.2523</td>\n",
       "      <td>9875.4682</td>\n",
       "      <td>10004.9059</td>\n",
       "      <td>868.4888</td>\n",
       "      <td>1104.5370</td>\n",
       "      <td>8880.3355</td>\n",
       "      <td>5.1878</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0131</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optical Handwritten</th>\n",
       "      <td>10922.5395</td>\n",
       "      <td>11446.8281</td>\n",
       "      <td>2283.8477</td>\n",
       "      <td>182.5983</td>\n",
       "      <td>418.5857</td>\n",
       "      <td>706.4299</td>\n",
       "      <td>22.3670</td>\n",
       "      <td>23.4406</td>\n",
       "      <td>4.6768</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>1.4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wine</th>\n",
       "      <td>45.6047</td>\n",
       "      <td>2856.4433</td>\n",
       "      <td>400.0693</td>\n",
       "      <td>26.0710</td>\n",
       "      <td>262.8928</td>\n",
       "      <td>75.6672</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>62.6349</td>\n",
       "      <td>8.7725</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>5.7646</td>\n",
       "      <td>1.6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satimage</th>\n",
       "      <td>6144.0592</td>\n",
       "      <td>8897.3865</td>\n",
       "      <td>1487.6289</td>\n",
       "      <td>109.0923</td>\n",
       "      <td>346.0239</td>\n",
       "      <td>535.6561</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1672</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.0602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vehicle</th>\n",
       "      <td>128.0892</td>\n",
       "      <td>1976.9125</td>\n",
       "      <td>289.4492</td>\n",
       "      <td>71.1585</td>\n",
       "      <td>306.8428</td>\n",
       "      <td>182.1980</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letter</th>\n",
       "      <td>7.4807</td>\n",
       "      <td>8863.3945</td>\n",
       "      <td>5838.2375</td>\n",
       "      <td>16.6882</td>\n",
       "      <td>254.1488</td>\n",
       "      <td>560.2539</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1184.8406</td>\n",
       "      <td>780.4437</td>\n",
       "      <td>2.2308</td>\n",
       "      <td>33.9741</td>\n",
       "      <td>74.8936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Segment</th>\n",
       "      <td>363.9657</td>\n",
       "      <td>963.7840</td>\n",
       "      <td>101.1305</td>\n",
       "      <td>58.1969</td>\n",
       "      <td>294.3508</td>\n",
       "      <td>81.6668</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motion Sense</th>\n",
       "      <td>95.0598</td>\n",
       "      <td>195.5569</td>\n",
       "      <td>33.9801</td>\n",
       "      <td>46.5919</td>\n",
       "      <td>282.6609</td>\n",
       "      <td>12.3158</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>1.4454</td>\n",
       "      <td>0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glass</th>\n",
       "      <td>710.3494</td>\n",
       "      <td>10518.1219</td>\n",
       "      <td>178.0682</td>\n",
       "      <td>52.9585</td>\n",
       "      <td>289.9049</td>\n",
       "      <td>137.8877</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>14.8070</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>5191.6265</td>\n",
       "      <td>12221.6016</td>\n",
       "      <td>1624.5267</td>\n",
       "      <td>121.9072</td>\n",
       "      <td>358.5355</td>\n",
       "      <td>1045.5729</td>\n",
       "      <td>2.3667</td>\n",
       "      <td>91.0933</td>\n",
       "      <td>53.4437</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>9.2419</td>\n",
       "      <td>5.5108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Absolute                                            \\\n",
       "                        Wisard          RF        KNN   MLP-1L    MLP-2L   \n",
       "Dry Bean               60.2301    305.8702   110.9039  81.8907  317.5171   \n",
       "Image Segmentation    945.9019  14015.5705  1446.8768  62.0370  299.4306   \n",
       "Iris                   51.7587    781.1236    29.1660  44.5428  282.0652   \n",
       "Rice                  139.1652    504.8834    26.9375  71.6205  308.5584   \n",
       "Sepsis                  2.8800    156.1860    10.8428  26.9556  263.9021   \n",
       "Yeast                7025.0604 111966.4944  2125.8564 109.7174  346.6115   \n",
       "Breast Cancer       51232.2523   9875.4682 10004.9059 868.4888 1104.5370   \n",
       "Optical Handwritten 10922.5395  11446.8281  2283.8477 182.5983  418.5857   \n",
       "Wine                   45.6047   2856.4433   400.0693  26.0710  262.8928   \n",
       "Satimage             6144.0592   8897.3865  1487.6289 109.0923  346.0239   \n",
       "Vehicle               128.0892   1976.9125   289.4492  71.1585  306.8428   \n",
       "Letter                  7.4807   8863.3945  5838.2375  16.6882  254.1488   \n",
       "Segment               363.9657    963.7840   101.1305  58.1969  294.3508   \n",
       "Motion Sense           95.0598    195.5569    33.9801  46.5919  282.6609   \n",
       "Glass                 710.3494  10518.1219   178.0682  52.9585  289.9049   \n",
       "Mean                 5191.6265  12221.6016  1624.5267 121.9072  358.5355   \n",
       "\n",
       "                              Relative                                    \\\n",
       "                          SVM   Wisard        RF      KNN MLP-1L  MLP-2L   \n",
       "Dry Bean              32.1240   0.1969    1.0000   0.3626 0.2677  1.0381   \n",
       "Image Segmentation  1466.3193   1.0000   14.8172   1.5296 0.0656  0.3166   \n",
       "Iris                  20.8877   0.0663    1.0000   0.0373 0.0570  0.3611   \n",
       "Rice                  29.1854   1.0000    3.6279   0.1936 0.5146  2.2172   \n",
       "Sepsis                 3.8918   1.0000   54.2310   3.7648 9.3595 91.6323   \n",
       "Yeast               2958.7748   0.0627    1.0000   0.0190 0.0010  0.0031   \n",
       "Breast Cancer       8880.3355   5.1878    1.0000   1.0131 0.0879  0.1118   \n",
       "Optical Handwritten  706.4299  22.3670   23.4406   4.6768 0.3739  0.8572   \n",
       "Wine                  75.6672   1.0000   62.6349   8.7725 0.5717  5.7646   \n",
       "Satimage             535.6561   0.6905    1.0000   0.1672 0.0123  0.0389   \n",
       "Vehicle              182.1980   0.0648    1.0000   0.1464 0.0360  0.1552   \n",
       "Letter               560.2539   1.0000 1184.8406 780.4437 2.2308 33.9741   \n",
       "Segment               81.6668   0.3776    1.0000   0.1049 0.0604  0.3054   \n",
       "Motion Sense          12.3158   0.4861    1.0000   0.1738 0.2383  1.4454   \n",
       "Glass                137.8877   1.0000   14.8070   0.2507 0.0746  0.4081   \n",
       "Mean                1045.5729   2.3667   91.0933  53.4437 0.9301  9.2419   \n",
       "\n",
       "                             \n",
       "                        SVM  \n",
       "Dry Bean             0.1050  \n",
       "Image Segmentation   1.5502  \n",
       "Iris                 0.0267  \n",
       "Rice                 0.2097  \n",
       "Sepsis               1.3513  \n",
       "Yeast                0.0264  \n",
       "Breast Cancer        0.8992  \n",
       "Optical Handwritten  1.4466  \n",
       "Wine                 1.6592  \n",
       "Satimage             0.0602  \n",
       "Vehicle              0.0922  \n",
       "Letter              74.8936  \n",
       "Segment              0.0847  \n",
       "Motion Sense         0.0630  \n",
       "Glass                0.1941  \n",
       "Mean                 5.5108  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_df = raw_relative_table(df, \"model_size\", \"model_size_relative\", order_of_models)\n",
    "size_df[\"Absolute\"] = size_df[\"Absolute\"] / 1024\n",
    "size_df.index = order_of_datasets\n",
    "write_latex_table(\"size_table.tex\", size_df.to_latex(float_format=\"%.2f\"))\n",
    "size_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv written to results_relative_pareto.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>model_size</th>\n",
       "      <th>model_size_std</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_std</th>\n",
       "      <th>performance_metric</th>\n",
       "      <th>accuracy_relative</th>\n",
       "      <th>f1_relative</th>\n",
       "      <th>model_size_relative</th>\n",
       "      <th>metric_relative</th>\n",
       "      <th>pareto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Wisard</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>61675.6667</td>\n",
       "      <td>64519.6794</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>113565.6000</td>\n",
       "      <td>110.9090</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>MLP-1L</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>83856.0667</td>\n",
       "      <td>755.9721</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>MLP-2L</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>325137.5333</td>\n",
       "      <td>385.8725</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>1.0381</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>313211.1333</td>\n",
       "      <td>20666.8041</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>32895.0000</td>\n",
       "      <td>1392.8819</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Wisard</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>968603.5333</td>\n",
       "      <td>443718.5251</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>1481601.8000</td>\n",
       "      <td>60.8210</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>1.5296</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>MLP-1L</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>63525.8667</td>\n",
       "      <td>247.8536</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.3987</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.3987</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>MLP-2L</td>\n",
       "      <td>0.4398</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>306616.9333</td>\n",
       "      <td>270.8753</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>0.3166</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>14351944.2000</td>\n",
       "      <td>174843.0306</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>14.8172</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>1501511.0000</td>\n",
       "      <td>2227.9318</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.6291</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>1.5502</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset   model  accuracy  accuracy_std     f1  f1_std  \\\n",
       "0   Breast Cancer  Wisard    0.9537        0.0179 0.9537  0.0177   \n",
       "2   Breast Cancer     KNN    0.9315        0.0294 0.9308  0.0307   \n",
       "3   Breast Cancer  MLP-1L    0.9251        0.0420 0.9245  0.0424   \n",
       "4   Breast Cancer  MLP-2L    0.9045        0.0294 0.9037  0.0300   \n",
       "6   Breast Cancer      RF    0.9637        0.0141 0.9635  0.0144   \n",
       "8   Breast Cancer     SVM    0.9174        0.0169 0.9155  0.0184   \n",
       "9        Dry Bean  Wisard    0.9027        0.0040 0.9028  0.0035   \n",
       "11       Dry Bean     KNN    0.6562        0.1059 0.6526  0.1042   \n",
       "12       Dry Bean  MLP-1L    0.4367        0.1268 0.3599  0.1272   \n",
       "13       Dry Bean  MLP-2L    0.4398        0.0603 0.3804  0.0510   \n",
       "15       Dry Bean      RF    0.8317        0.1315 0.8322  0.1308   \n",
       "17       Dry Bean     SVM    0.5679        0.1055 0.5391  0.0888   \n",
       "\n",
       "      model_size  model_size_std  metric  metric_std performance_metric  \\\n",
       "0     61675.6667      64519.6794  0.9537      0.0177                 f1   \n",
       "2    113565.6000        110.9090  0.9308      0.0307                 f1   \n",
       "3     83856.0667        755.9721  0.9245      0.0424                 f1   \n",
       "4    325137.5333        385.8725  0.9037      0.0300                 f1   \n",
       "6    313211.1333      20666.8041  0.9635      0.0144                 f1   \n",
       "8     32895.0000       1392.8819  0.9155      0.0184                 f1   \n",
       "9    968603.5333     443718.5251  0.9028      0.0035                 f1   \n",
       "11  1481601.8000         60.8210  0.6526      0.1042                 f1   \n",
       "12    63525.8667        247.8536  0.3599      0.1272                 f1   \n",
       "13   306616.9333        270.8753  0.3804      0.0510                 f1   \n",
       "15 14351944.2000     174843.0306  0.8322      0.1308                 f1   \n",
       "17  1501511.0000       2227.9318  0.5391      0.0888                 f1   \n",
       "\n",
       "    accuracy_relative  f1_relative  model_size_relative  metric_relative  \\\n",
       "0              0.9896       0.9898               0.1969           0.9898   \n",
       "2              0.9666       0.9660               0.3626           0.9660   \n",
       "3              0.9600       0.9595               0.2677           0.9595   \n",
       "4              0.9386       0.9379               1.0381           0.9379   \n",
       "6              1.0000       1.0000               1.0000           1.0000   \n",
       "8              0.9520       0.9501               0.1050           0.9501   \n",
       "9              1.0000       1.0000               1.0000           1.0000   \n",
       "11             0.7270       0.7229               1.5296           0.7229   \n",
       "12             0.4838       0.3987               0.0656           0.3987   \n",
       "13             0.4872       0.4213               0.3166           0.4213   \n",
       "15             0.9214       0.9218              14.8172           0.9218   \n",
       "17             0.6291       0.5971               1.5502           0.5971   \n",
       "\n",
       "   pareto  \n",
       "0    True  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  \n",
       "6    True  \n",
       "8    True  \n",
       "9    True  \n",
       "11  False  \n",
       "12   True  \n",
       "13   True  \n",
       "15  False  \n",
       "17  False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify Pareto frontier\n",
    "def is_pareto_efficient(costs):\n",
    "    is_efficient = np.ones(costs.shape[0], dtype=bool)\n",
    "    for i, c in enumerate(costs):\n",
    "        if is_efficient[i]:\n",
    "            is_efficient[is_efficient] = np.any(costs[is_efficient] < c, axis=1)\n",
    "            is_efficient[i] = True  # Keep the current point\n",
    "    return is_efficient\n",
    "\n",
    "for dset_name, dset_df in df.groupby(\"dataset\"):\n",
    "    costs = dset_df[[\"model_size\", \"metric\"]].to_numpy()\n",
    "    # Invert metric (lower is better)\n",
    "    costs[:, 1] = 1 / costs[:, 1]\n",
    "    pareto = is_pareto_efficient(costs)\n",
    "    df.loc[dset_df.index, \"pareto\"] = pareto\n",
    "    \n",
    "df.to_csv(\"results_relative_pareto.csv\", index=False)\n",
    "print(f\"Csv written to results_relative_pareto.csv\")\n",
    "df.head(n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wisard has competitive results with SKLearn\n",
    "\n",
    "Here we show that the dict-wisard has competitive performance with the\n",
    "classical machine learning algorithms.\n",
    "\n",
    "To do that, we plot the accuracy of the wisard and sklearn algorithms for each\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the best performance for each dataset and model\n",
    "best_metric_df = (\n",
    "    results.groupby([\"dataset\", \"model\"])\n",
    "    .apply(lambda group: group.loc[group[\"metric\"].idxmax()])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "best_metric_df.value_counts(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'results' DataFrame with columns: 'dataset', 'model', 'accuracy'\n",
    "\n",
    "# Create a grouped bar chart for accuracy per model and dataset\n",
    "fig_grouped_bar = px.bar(\n",
    "    best_metric_df,\n",
    "    x=\"dataset\",\n",
    "    y=\"metric\",\n",
    "    error_y=\"metric_std\",\n",
    "    color=\"model\",\n",
    "    #  title='Metric Comparison by Model and Dataset',\n",
    "    labels={\"metric\": \"Performance\", \"dataset\": \"Dataset\", \"model\": \"\"},\n",
    "    barmode=\"group\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Prism,\n",
    ")\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "fig_grouped_bar.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\", yanchor=\"top\", y=1.20, xanchor=\"center\", x=0.5\n",
    "    ),\n",
    "    height=400,\n",
    "    width=2480 / 2.5,\n",
    "    font=dict(family=\"Times New Roman\", size=14),\n",
    ")\n",
    "\n",
    "write_figure(\"models_performance.pdf\", fig_grouped_bar)\n",
    "fig_grouped_bar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'results' DataFrame with columns: 'dataset', 'model', 'accuracy'\n",
    "\n",
    "# Create a grouped horizontal bar chart for accuracy per model and dataset with reversed bar groups\n",
    "fig_grouped_bar = px.bar(\n",
    "    best_metric_df,\n",
    "    y=\"dataset\",\n",
    "    x=\"metric\",\n",
    "    error_x=\"metric_std\",\n",
    "    color=\"model\",\n",
    "    #  title='Metric Comparison by Model and Dataset',\n",
    "    labels={\"metric\": \"Performance\", \"dataset\": \"Dataset\", \"model\": \"\"},\n",
    "    barmode=\"group\",\n",
    "    orientation='h',\n",
    "    color_discrete_sequence=px.colors.qualitative.Prism,\n",
    ")\n",
    "\n",
    "\n",
    "# Reverse the order of the bar groups\n",
    "fig_grouped_bar.update_layout(\n",
    "    yaxis=dict(autorange=\"reversed\"),\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig_grouped_bar.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\", yanchor=\"top\", y=1.05, xanchor=\"center\", x=0.5\n",
    "    ),\n",
    "    height=1200,\n",
    "    width=2480 / 4,\n",
    "    font=dict(family=\"Times New Roman\", size=14),\n",
    ")\n",
    "\n",
    "write_figure(\"models_performance_horizontal.pdf\", fig_grouped_bar)\n",
    "fig_grouped_bar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times per dataset, wisard is the best model\n",
    "\n",
    "print(\"How many times per dataset, each model is the best?\")\n",
    "best_metric_df.loc[\n",
    "    best_metric_df.groupby(\"dataset\")[\"metric\"].idxmax()\n",
    "].value_counts(\"model\").to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wisard has competitive results with SKLearn and is smallest\n",
    "\n",
    "Here we show that costing up to 2% of performance, the dict-wisard is much\n",
    "smaller than the sklearn algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to 2% of accuracy loss\n",
    "metric_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results and filter bloom filter results\n",
    "results = base_results.copy()\n",
    "results = results[\n",
    "    (results[\"model\"] != \"wisard\") | (results[\"config_name\"] == \"Dict\")\n",
    "]\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the best performance for each dataset and model\n",
    "best_metric_dataset_model = (\n",
    "    results.groupby([\"dataset\", \"model\"])\n",
    "    .apply(lambda group: group.loc[group[\"metric\"].idxmax()])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "best_metric_dataset_model.value_counts(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the model_size_ratio column. This column is the ratio between the model\n",
    "# size of each model and the model size of the best model for each dataset\n",
    "temp = []\n",
    "\n",
    "for dset_name, dset_df in best_metric_dataset_model.groupby(\"dataset\"):\n",
    "    best_row = dset_df.sort_values(by=\"metric\", ascending=False).iloc[0]\n",
    "    dset_df[\"model_size_ratio\"] = dset_df[\"model_size\"] / best_row[\"model_size\"]\n",
    "    # Min max normalization\n",
    "    dset_df[\"normalized_model_size_ratio\"] = (\n",
    "        dset_df[\"model_size_ratio\"] - dset_df[\"model_size_ratio\"].min()\n",
    "    ) / (dset_df[\"model_size_ratio\"].max() - dset_df[\"model_size_ratio\"].min())\n",
    "    dset_df[\"best_tradeoff\"] = False\n",
    "\n",
    "    best_tradeoff = (\n",
    "        dset_df[dset_df[\"metric\"] >= best_row[\"metric\"] - metric_threshold]\n",
    "        .sort_values(by=\"normalized_model_size_ratio\", ascending=True)\n",
    "        .iloc[0]\n",
    "    )\n",
    "    dset_df.loc[best_tradeoff.name, \"best_tradeoff\"] = True\n",
    "\n",
    "    temp.append(dset_df)\n",
    "\n",
    "best_metric_dataset_model = pd.concat(temp)\n",
    "best_metric_dataset_model.head(n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 100)\n",
    "dfs = {}\n",
    "for dset_name, dset_df in best_metric_dataset_model.groupby(\"dataset\"):\n",
    "    dset_df[\"model_size\"] = (dset_df[\"model_size\"] / 1024)\n",
    "    max_val = dset_df[\"metric\"].max()\n",
    "    max_size =  dset_df[\"model_size\"].max()\n",
    "    dset_df[\"relative performance\"] = dset_df[\"metric\"]  / max_val\n",
    "    dset_df[\"relative size\"] = dset_df[\"model_size\"]  / max_size\n",
    "    # dset_df.index = dset_df[\"model\"]\n",
    "    dset_df = dset_df[[\"model\", \"metric\",  \"model_size\", \"relative performance\", \"relative size\", \"accuracy\", \"f1\"]]\n",
    "    dfs[dset_name] = dset_df\n",
    "    \n",
    "result_df = pd.concat(dfs.values(), keys=dfs.keys())\n",
    "result_df.reset_index(level=0, inplace=True)\n",
    "result_df = result_df.rename(columns={\"level_0\": \"dataset\"})\n",
    "result_df.to_csv(\"temp.csv\", index=False)\n",
    "print(f\"Results written to temp.csv\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pivot the DataFrame to create the raw metric table\n",
    "# table_df_raw = result_df.pivot(index='dataset', columns='model', values='metric')\n",
    "\n",
    "# # Pivot the DataFrame to create the relative performance metric table\n",
    "# table_df_relative_performance = result_df.pivot(index='dataset', columns='model', values='relative performance')\n",
    "\n",
    "# # Join the two tables based on dataset\n",
    "# joined_df = table_df_raw.join(table_df_relative_performance, lsuffix=\"_raw\", rsuffix=\"_relative_performance\")\n",
    "\n",
    "\n",
    "# # joined_df.to_csv(\"temp.csv\", index=True)\n",
    "\n",
    "# # joined_df = joined_df.reset_index()\n",
    "\n",
    "# joined_df = joined_df.rename_axis(None, axis=1).reset_index()\n",
    "# # joined_df.index = range(len(joined_df))\n",
    "\n",
    "# # joined_df.columns = joined_df.columns.to_list()\n",
    "\n",
    "\n",
    "# raw_df = joined_df[['dataset', 'knn_raw', 'mlp_raw', 'random-forest_raw', 'svm_raw', 'wisard_raw']]\n",
    "# relative_df = joined_df[['dataset', 'knn_relative_performance', 'mlp_relative_performance', 'random-forest_relative_performance', 'svm_relative_performance', 'wisard_relative_performance']]\n",
    "\n",
    "# raw_df[\"dataset\"] = raw_df[\"dataset\"].str.replace(\"_\", \" \")\n",
    "# relative_df[\"dataset\"] = relative_df[\"dataset\"].str.replace(\"_\", \" \")\n",
    "# raw_df.columns = raw_df.columns.str.replace(\"-\", \" \")\n",
    "# relative_df.columns = relative_df.columns.str.replace(\"-\", \" \")\n",
    "\n",
    "# line = {\"dataset\": \"Mean\"}\n",
    "# for c in raw_df.columns:\n",
    "#     if c != \"dataset\":\n",
    "#         line[c] = raw_df[c].mean()\n",
    "# raw_df.loc[len(raw_df)] = line\n",
    "\n",
    "# line = {\"dataset\": \"Mean\"}\n",
    "# for c in relative_df.columns:\n",
    "#     if c != \"dataset\":\n",
    "#         line[c] = relative_df[c].mean()\n",
    "# relative_df.loc[len(relative_df)] = line\n",
    "\n",
    "\n",
    "# # Setting the dataset column as the index\n",
    "# raw_df.set_index('dataset', inplace=True)\n",
    "# relative_df.set_index('dataset', inplace=True)\n",
    "\n",
    "# # # Concatenating the DataFrames\n",
    "# final_df = pd.concat([raw_df, relative_df], axis=1)\n",
    "\n",
    "# # # Renaming the columns\n",
    "# final_df.columns = pd.MultiIndex.from_product([['Raw', 'Relative'], raw_df.columns.str.split('_').str[0]])\n",
    "\n",
    "# write_latex_table(\"performance_table.tex\", final_df.to_latex(float_format=\"%.2f\"))\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_line(df):\n",
    "    line = {\"dataset\": \"Mean\"}\n",
    "    for c in df.columns:\n",
    "        if c != \"dataset\":\n",
    "            line[c] = df[c].mean()\n",
    "    df.loc[len(df)] = line\n",
    "    return df\n",
    "\n",
    "def raw_relative_table(df, raw_metric, relative_metric):\n",
    "    # Pivot the DataFrame to create the raw metric table and relative table\n",
    "    raw_df = (\n",
    "        df.pivot(index=\"dataset\", columns=\"model\", values=raw_metric)\n",
    "        .rename_axis(None, axis=1)\n",
    "        .reset_index()\n",
    "    )\n",
    "    raw_df[\"dataset\"] = raw_df[\"dataset\"].str.replace(\"_\", \" \")\n",
    "    raw_df.columns = raw_df.columns.str.replace(\"-\", \" \")\n",
    "    raw_df = raw_df[[\"dataset\", \"svm\", \"mlp\", \"knn\", \"random forest\", \"wisard\"]]\n",
    "    raw_df = add_mean_line(raw_df)\n",
    "    raw_df.set_index(\"dataset\", inplace=True)\n",
    "\n",
    "    relative_df = (\n",
    "        df.pivot(\n",
    "            index=\"dataset\", columns=\"model\", values=relative_metric\n",
    "        )\n",
    "        .rename_axis(None, axis=1)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    relative_df[\"dataset\"] = relative_df[\"dataset\"].str.replace(\"_\", \" \")\n",
    "    relative_df.columns = relative_df.columns.str.replace(\"-\", \" \")\n",
    "    relative_df = relative_df[[\"dataset\", \"svm\", \"mlp\", \"knn\", \"random forest\", \"wisard\"]]\n",
    "    relative_df = add_mean_line(relative_df)\n",
    "    relative_df.set_index(\"dataset\", inplace=True)\n",
    "    \n",
    "    # Concatenating the DataFrames\n",
    "    final_df = pd.concat([raw_df, relative_df], axis=1)\n",
    "\n",
    "    final_df.columns = pd.MultiIndex.from_product(\n",
    "        [[\"Absolute\", \"Relative\"], raw_df.columns.str.split(\"_\").str[0]]\n",
    "    )\n",
    "    return final_df\n",
    "\n",
    "performance_df = raw_relative_table(result_df.copy(), \"metric\", \"relative performance\")\n",
    "order_of_datasets = performance_df[\"Relative\"][\"wisard\"].sort_values(ascending=False).keys().to_list()\n",
    "order_of_datasets.remove(\"Mean\")\n",
    "order_of_datasets.append(\"Mean\")\n",
    "performance_df.index = order_of_datasets\n",
    "write_latex_table(\"performance_table.tex\", performance_df.to_latex(float_format=\"%.2f\"))\n",
    "\n",
    "size_df = raw_relative_table(result_df.copy(), \"model_size\", \"relative size\")\n",
    "size_df.index = order_of_datasets\n",
    "write_latex_table(\"size_table.tex\", size_df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "\n",
    "# def belongs_to_pareto(df, model):\n",
    "#     metric = df[df[\"model\"] == model][\"metric\"].iloc[0]\n",
    "#     size = df[df[\"model\"] == model][\"model_size\"].iloc[0]\n",
    "    \n",
    "#     for r_index, row in df.iterrows():\n",
    "#         if row[\"metric\"] > metric and row[\"model_size\"] < size:\n",
    "#             return False\n",
    "        \n",
    "#     return True\n",
    "    \n",
    "# columns = result_df[\"dataset\"].unique()\n",
    "    \n",
    "\n",
    "# models = [\"wisard\", \"random-forest\", \"svm\", \"mlp\", \"knn\"]\n",
    "# for c in columns:\n",
    "#     x_df = result_df[result_df[\"dataset\"] == c]\n",
    "#     if belongs_to_pareto(x_df, \"wisard\"):\n",
    "#         print(f\"Wisard belongs to pareto in {c}\")\n",
    "#         # x_df.index = x_df.index.str.upper()\n",
    "    \n",
    "#     lines = []\n",
    "#     for m in models:\n",
    "#         line = x_df[x_df[\"model\"] == m]\n",
    "#         if belongs_to_pareto(x_df, m):\n",
    "#             print(f\"Wisard belongs to pareto in {c}\")\n",
    "#             line[\"pareto\"] = True\n",
    "#         else:\n",
    "#             line[\"pareto\"] = False\n",
    "#         lines.append(line)\n",
    "        \n",
    "        \n",
    "#     x_df = pd.concat(lines)\n",
    "    \n",
    "#     dfs.append(x_df)\n",
    "    \n",
    "# n = pd.concat(dfs).reset_index()\n",
    "    \n",
    "# # n[\"dataset\"] = n[\"level_0\"]\n",
    "# # n[\"pareto\"] = n[\"pareto\"].astype(int)\n",
    "# n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume 'results' DataFrame with columns: 'dataset', 'model', 'accuracy'\n",
    "\n",
    "# # Create a grouped horizontal bar chart for accuracy per model and dataset with reversed bar groups\n",
    "# fig_grouped_bar = px.bar(\n",
    "#     n,\n",
    "#     y=\"dataset\",\n",
    "#     x=\"metric\",\n",
    "#     # error_x=\"metric_std\",\n",
    "#     color=\"model\",\n",
    "#     #  title='Metric Comparison by Model and Dataset',\n",
    "#     labels={\"metric\": \"Performance\", \"dataset\": \"Dataset\", \"model\": \"\"},\n",
    "#     barmode=\"group\",\n",
    "#     orientation='h',\n",
    "#     color_discrete_sequence=px.colors.qualitative.Prism,\n",
    "# )\n",
    "\n",
    "\n",
    "# # Reverse the order of the bar groups\n",
    "# fig_grouped_bar.update_layout(\n",
    "#     yaxis=dict(autorange=\"reversed\"),\n",
    "# )\n",
    "\n",
    "# # Display the plot\n",
    "# fig_grouped_bar.update_layout(\n",
    "#     legend=dict(\n",
    "#         orientation=\"h\", yanchor=\"top\", y=1.05, xanchor=\"center\", x=0.5\n",
    "#     ),\n",
    "#     height=1200,\n",
    "#     width=2480 / 4,\n",
    "#     font=dict(family=\"Times New Roman\", size=14),\n",
    "# )\n",
    "\n",
    "# write_figure(\"models_performance_horizontal.pdf\", fig_grouped_bar)\n",
    "# fig_grouped_bar.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Pareto frontier\n",
    "def is_pareto_efficient(costs):\n",
    "    is_efficient = np.ones(costs.shape[0], dtype=bool)\n",
    "    for i, c in enumerate(costs):\n",
    "        if is_efficient[i]:\n",
    "            is_efficient[is_efficient] = np.any(costs[is_efficient] < c, axis=1)\n",
    "            is_efficient[i] = True  # Keep the current point\n",
    "    return is_efficient\n",
    "\n",
    "for dset_name, dset_df in result_df.groupby(\"dataset\"):\n",
    "    costs = dset_df[[\"model_size\", \"metric\"]].to_numpy()\n",
    "    # Invert metric (lower is better)\n",
    "    costs[:, 1] = 1 / costs[:, 1]\n",
    "    pareto = is_pareto_efficient(costs)\n",
    "    result_df.loc[dset_df.index, \"pareto\"] = pareto\n",
    "    \n",
    "result_df.to_csv(\"temp.csv\", index=False)\n",
    "print(f\"Csv written to temp.csv\")\n",
    "result_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.groupby(\"model\").pareto.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'data' is our DataFrame\n",
    "data = result_df.copy()\n",
    "\n",
    "# dfs = []\n",
    "# for dset in order_of_datasets:\n",
    "#     x = data[data[\"dataset\"] == dset].copy()\n",
    "#     dfs.append(x)\n",
    "# data = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# Define marker symbols for each model\n",
    "marker_symbols = {\n",
    "    \"knn\": \"circle\",\n",
    "    \"mlp\": \"square\",\n",
    "    \"random-forest\": \"diamond\",\n",
    "    \"svm\": \"cross\",\n",
    "    \"wisard\": \"x\",\n",
    "}\n",
    "\n",
    "# Define model names for legend\n",
    "model_names = {\n",
    "    \"knn\": \"KNN\",\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"random-forest\": \"Random Forest\",\n",
    "    \"svm\": \"SVM\",\n",
    "    \"wisard\": \"Wisard\",\n",
    "}\n",
    "\n",
    "pareto_colors = {\n",
    "    True: px.colors.qualitative.Plotly[1],\n",
    "    False: px.colors.qualitative.Plotly[0],\n",
    "}\n",
    "\n",
    "# data[\"relative size\"] = np.log(data[\"relative size\"])\n",
    "\n",
    "fig = px.scatter(\n",
    "    data,\n",
    "    x=\"relative size\",\n",
    "    y=\"metric\",\n",
    "    symbol=\"model\",\n",
    "    symbol_map=marker_symbols,\n",
    "    color=\"pareto\",\n",
    "    color_discrete_map=pareto_colors,\n",
    "    facet_col=\"dataset\",\n",
    "    facet_col_wrap=3,\n",
    "    height=1000,\n",
    "    width=900,\n",
    "    facet_row_spacing=0.03,\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(size=7),\n",
    "    selector=dict(mode=\"markers\"),\n",
    "    showlegend=False,  # Hides the legend entries created by Plotly Express\n",
    ")\n",
    "\n",
    "for anno in fig[\"layout\"][\"annotations\"]:\n",
    "    anno[\"text\"] = anno[\"text\"].split(\"=\")[1].replace(\"_\", \" \")\n",
    "\n",
    "# Manually map symbols to names in the legend\n",
    "legend_labels = {\n",
    "    symbol: model_names[model] for model, symbol in marker_symbols.items()\n",
    "}\n",
    "\n",
    "# Create a custom legend\n",
    "custom_legend = []\n",
    "for symbol, model_name in legend_labels.items():\n",
    "    custom_legend.append(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                symbol=symbol, size=12, color=px.colors.qualitative.Plotly[0]\n",
    "            ),\n",
    "            name=model_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add custom legend to the figure\n",
    "for trace in custom_legend:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title=\"\",  # Set title to empty string to remove the legend title\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.07,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        traceorder=\"normal\",  # Set trace order to normal to arrange legend entries horizontally\n",
    "    ),\n",
    "    margin=dict(l=10, r=10, t=10, b=10),\n",
    "    font=dict(family=\"Times New Roman\", size=14),\n",
    ")\n",
    "\n",
    "write_figure(\"model_metric_size.pdf\", fig)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming 'data' is our DataFrame\n",
    "data = result_df.copy()\n",
    "\n",
    "# Define marker symbols for each model\n",
    "marker_symbols = {\n",
    "    \"knn\": \"circle\",\n",
    "    \"mlp\": \"square\",\n",
    "    \"random-forest\": \"diamond\",\n",
    "    \"svm\": \"cross\",\n",
    "    \"wisard\": \"x\",\n",
    "}\n",
    "\n",
    "# Define model names for legend\n",
    "model_names = {\n",
    "    \"knn\": \"KNN\",\n",
    "    \"mlp\": \"MLP\",\n",
    "    \"random-forest\": \"Random Forest\",\n",
    "    \"svm\": \"SVM\",\n",
    "    \"wisard\": \"Wisard\",\n",
    "}\n",
    "\n",
    "pareto_colors = {\n",
    "    True: px.colors.qualitative.Plotly[1],\n",
    "    False: px.colors.qualitative.Plotly[0],\n",
    "}\n",
    "\n",
    "\n",
    "rows = 5\n",
    "cols = 3\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data[\"relative size\"] = np.log(data[\"relative size\"])\n",
    "\n",
    "fig = px.scatter(\n",
    "    data,\n",
    "    x=\"relative size\",\n",
    "    y=\"metric\",\n",
    "    symbol=\"model\",\n",
    "    symbol_map=marker_symbols,\n",
    "    color=\"pareto\",\n",
    "    color_discrete_map=pareto_colors,\n",
    "    facet_col=\"dataset\",\n",
    "    facet_col_wrap=3,\n",
    "    height=1000,\n",
    "    width=900,\n",
    "    facet_row_spacing=0.03,\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(size=7),\n",
    "    selector=dict(mode=\"markers\"),\n",
    "    showlegend=False,  # Hides the legend entries created by Plotly Express\n",
    ")\n",
    "\n",
    "for anno in fig[\"layout\"][\"annotations\"]:\n",
    "    anno[\"text\"] = anno[\"text\"].split(\"=\")[1].replace(\"_\", \" \")\n",
    "\n",
    "# Manually map symbols to names in the legend\n",
    "legend_labels = {\n",
    "    symbol: model_names[model] for model, symbol in marker_symbols.items()\n",
    "}\n",
    "\n",
    "# Create a custom legend\n",
    "custom_legend = []\n",
    "for symbol, model_name in legend_labels.items():\n",
    "    custom_legend.append(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                symbol=symbol, size=12, color=px.colors.qualitative.Plotly[0]\n",
    "            ),\n",
    "            name=model_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add custom legend to the figure\n",
    "for trace in custom_legend:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        title=\"\",  # Set title to empty string to remove the legend title\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.07,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        traceorder=\"normal\",  # Set trace order to normal to arrange legend entries horizontally\n",
    "    ),\n",
    "    margin=dict(l=10, r=10, t=10, b=10),\n",
    "    font=dict(family=\"Times New Roman\", size=14),\n",
    ")\n",
    "\n",
    "write_figure(\"model_metric_size.pdf\", fig)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for dset_name, dset_df in best_metric_dataset_model.groupby(\"dataset\"):\n",
    "    max_val = dset_df[\"metric\"].max()\n",
    "    dset_df[\"model_size (KB)\"] = (dset_df[\"model_size\"] / 1024)\n",
    "    dset_df[\"relative performance\"] = dset_df[\"metric\"]  / max_val\n",
    "    dset_df = dset_df[[\"relative performance\", \"model_size (KB)\"]]\n",
    "    dfs[dset_name] = dset_df\n",
    "    \n",
    "result_df = pd.concat(dfs.values(), keys=dfs.keys()).reset_index()\n",
    "# result_df.reset_index(level=0, inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How many times per dataset, each model is the best tradeoff?\")\n",
    "best_metric_dataset_model[\n",
    "    best_metric_dataset_model.best_tradeoff == True\n",
    "].value_counts(\"model\").to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facets = 3\n",
    "cmap = px.colors.qualitative.Prism\n",
    "\n",
    "colors = {\n",
    "    name: cmap[i]\n",
    "    for i, name in enumerate(sorted(best_metric_dataset_model.model.unique()))\n",
    "}\n",
    "\n",
    "# Scatter plot for trade-off with normalized model size\n",
    "fig_tradeoff_normalized = px.scatter(\n",
    "    best_metric_dataset_model,\n",
    "    x=\"metric\",\n",
    "    y=\"normalized_model_size_ratio\",\n",
    "    color=\"model\",\n",
    "    facet_col=\"dataset\",\n",
    "    facet_col_wrap=facets,\n",
    "    # title=\"Trade-off Between Metric and Normalized Model Size Across Datasets\",\n",
    "    labels={\n",
    "        \"metric\": \"Performance\",\n",
    "        \"normalized_model_size_ratio\": \"Size Ratio (normalized)\",\n",
    "        \"model\": \"\",\n",
    "    },\n",
    "    facet_row_spacing=0.07,\n",
    "    width=1400,\n",
    "    height=800,\n",
    "    color_discrete_sequence=cmap,\n",
    ")\n",
    "\n",
    "\n",
    "fig_tradeoff_normalized.update_traces(\n",
    "    marker=dict(size=7.5),\n",
    ")\n",
    "\n",
    "fig_tradeoff_normalized.update_xaxes(showticklabels=True)\n",
    "\n",
    "fig_tradeoff_normalized.update_yaxes(showticklabels=True)\n",
    "\n",
    "fig_tradeoff_normalized.for_each_annotation(\n",
    "    lambda a: a.update(text=a.text.split(\"=\")[-1])\n",
    ")\n",
    "\n",
    "# fig_tradeoff_normalized.update_layout(\n",
    "#     legend=dict(\n",
    "#         orientation=\"h\", yanchor=\"bottom\", y=-0.15, xanchor=\"center\", x=0.5,\n",
    "#     ),\n",
    "\n",
    "# )\n",
    "\n",
    "fig_tradeoff_normalized.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        itemsizing=\"constant\",  # Set this to \"constant\" to show only one item for color\n",
    "        font=dict(family=\"Times New Roman\", size=14),\n",
    "    ),\n",
    "    height=1200,\n",
    "    width=2480 /2.5,\n",
    "    font=dict(family=\"Times New Roman\", size=14),\n",
    ")\n",
    "num_rows = len(results.dataset.unique()) // facets\n",
    "num_cols = facets\n",
    "# datasets = list(sorted(results.dataset.unique(), reverse=False))\n",
    "\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "       \n",
    "        facet = r * num_cols + c\n",
    "        dset = fig_tradeoff_normalized.layout.annotations[facet]['text']\n",
    "\n",
    "        x_line = (\n",
    "            results[results[\"dataset\"] == dset][\"metric\"].max()\n",
    "            - metric_threshold\n",
    "        )\n",
    "        \n",
    " # Scatter plot for best tradeoff points with a cross\n",
    "        best_tradeoff_points = best_metric_dataset_model[\n",
    "            (best_metric_dataset_model[\"dataset\"] == dset)\n",
    "            & (best_metric_dataset_model[\"best_tradeoff\"] == True)\n",
    "        ]\n",
    "        \n",
    "        best_tradeoff_model = best_tradeoff_points.model.iloc[0]\n",
    "        \n",
    "        # print(f\"Facet {facet}: {dset} - {best_tradeoff_model}. Max: {results[results['dataset'] == dset]['metric'].max()}, line: {x_line}\")\n",
    "        \n",
    "        fig_tradeoff_normalized.add_trace(\n",
    "            go.Scatter(\n",
    "                x=best_tradeoff_points[\"metric\"],\n",
    "                y=best_tradeoff_points[\"normalized_model_size_ratio\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    symbol=\"x\",\n",
    "                    color=colors[best_tradeoff_model]\n",
    "                ),\n",
    "                showlegend=False,  # To not duplicate in the legend\n",
    "            ),\n",
    "            row=r + 1,\n",
    "            col=c + 1,\n",
    "        )\n",
    "        \n",
    "        fig_tradeoff_normalized.add_vline(\n",
    "            x=x_line, line_dash=\"dot\", row=r + 1, col=c + 1, line_width=1\n",
    "        )\n",
    "\n",
    "# Display the plot\n",
    "fig_tradeoff_normalized.show()\n",
    "\n",
    "write_figure(\"performance_size_tradeoff_normalized.pdf\", fig_tradeoff_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric_dataset_model[\n",
    "    best_metric_dataset_model.best_tradeoff == True\n",
    "][[\"dataset\", \"model\", \"config_name\", \"metric\", \"model_size\", \"model_size_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric_dataset_model[best_metric_dataset_model [\"dataset\"] == \"iris\"].dropna(axis=1)[[\"model\", \"metric\", \"model_size\", \"model_size_ratio\", \"normalized_model_size_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric_dataset_model[[\"dataset\", \"model\", \"config_name\", \"metric\", \"model_size\", \"model_size_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric_dataset_model[\n",
    "    (best_metric_dataset_model.best_tradeoff == True) & (best_metric_dataset_model.model == \"wisard\")\n",
    "][\"model_size_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_info = best_metric_dataset_model[best_metric_dataset_model.model == \"wisard\"]\n",
    "encoder_info = encoder_info[[\"dataset\", \"encoder\", \"resolution\", \"tuple_size\", \"bleach\"]].reset_index(drop=True)\n",
    "encoder_info.rename(columns={\"encoder\": \"Encoder\", \"resolution\": \"Resolution\", \"tuple_size\": \"Tuple Size\", \"bleach\": \"Bleach\"}, inplace=True)\n",
    "encoder_info[\"Encoder\"] = encoder_info[\"Encoder\"].apply(lambda x: \"Distributive Thermometer\" if x == \"distributive-thermometer\" else \"Thermometer\")\n",
    "encoder_info[\"Resolution\"] = encoder_info[\"Resolution\"].astype(int)\n",
    "encoder_info[\"Tuple Size\"] = encoder_info[\"Tuple Size\"].astype(int)\n",
    "encoder_info[\"Bleach\"] = encoder_info[\"Bleach\"].astype(int)\n",
    "encoder_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_str = encoder_info.to_latex(\n",
    "    index=False,\n",
    "    escape=True,\n",
    "    caption=\"Parameters used for each experiment\",\n",
    "    label=\"tab:experiment-parameters\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "write_latex_table(\"experiment_parameters.tex\", latex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select the wisard with best bloom filter\n",
    "\n",
    "Here we show that, costing up to 1% of performance of the best dict-wisard, a \n",
    "space-efficient bloom filter achieves the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to 1% of accuracy loss\n",
    "metric_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = base_results.copy()\n",
    "best_results = best_metric_dataset_model.copy()\n",
    "\n",
    "results = results[results[\"model\"] == \"wisard\"]\n",
    "best_results = best_results[best_results[\"model\"] == \"wisard\"]\n",
    "\n",
    "results[\"bloom-filter\"] = results[\"config_name\"].apply(lambda x: x.split(\" \")[0])\n",
    "best_results[\"bloom-filter\"] = best_results[\"config_name\"].apply(lambda x: x.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "\n",
    "for dset_name, dset_df in results.groupby(\"dataset\"):\n",
    "    best_model = best_results[best_results[\"dataset\"] == dset_name].iloc[0]\n",
    "    # print(f\"*** Dataset: {dset_name} with metric: {best_model['metric']} and model size: {int(best_model['model_size'])}\")\n",
    "    bests = dset_df[dset_df[\"metric\"] >= best_model[\"metric\"] - metric_threshold]\n",
    "    bests[\"metric_improvement\"] = bests[\"metric\"]/ best_model[\"metric\"]\n",
    "    bests[\"model_size_improvement\"] = bests[\"model_size\"]/ best_model[\"model_size\"]\n",
    "    bests[\"best_metric\"]  = best_model[\"metric\"]\n",
    "    bests[\"best_model_size\"]  = best_model[\"model_size\"]\n",
    "    temp.append(bests)\n",
    "    \n",
    "results = pd.concat(temp, ignore_index=True)\n",
    "results.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results.loc[results.groupby(\"dataset\")[\"model_size_improvement\"].idxmin()]\n",
    "best_results[\"bloom-filter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_table = best_results.sort_values(by=[\"dataset\"])[[\"dataset\", \"config_name\", \"model_size_improvement\"]]\n",
    "\n",
    "best_results_table.rename(\n",
    "    columns={\n",
    "        \"dataset\": \"Dataset\",\n",
    "        \"config_name\": \"Bloom Filter\",\n",
    "        \"model_size_improvement\": \"Size Ratio\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "best_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_str = best_results_table.to_latex(\n",
    "    index=False,\n",
    "    escape=True,\n",
    "    caption=\"Best Bloom Filter configuration for each dataset\",\n",
    "    label=\"tab:best_bloom_filter\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "write_latex_table(\"best_bloom_filter.tex\", latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_table = best_results.sort_values(by=[\"dataset\"])[[\"dataset\", \"bloom-filter\", \"config_name\", \"model_size_improvement\"]]\n",
    "best_results_table.groupby(\"bloom-filter\")[\"model_size_improvement\"].agg([\"mean\", \"std\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select the wisard with best aggregated bloom filter\n",
    "\n",
    "Here we show that, costing up to 1% of performance of the best dict-wisard, a \n",
    "space-efficient bloom filter achieves the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up to 2% of accuracy loss\n",
    "metric_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = base_results.copy()\n",
    "best_results = best_metric_dataset_model.copy()\n",
    "\n",
    "results = results[results[\"model\"] == \"wisard\"]\n",
    "best_results = best_results[best_results[\"model\"] == \"wisard\"]\n",
    "\n",
    "results[\"bloom-filter\"] = results[\"config_name\"].apply(lambda x: x.split(\" \")[0])\n",
    "best_results[\"bloom-filter\"] = best_results[\"config_name\"].apply(lambda x: x.split(\" \")[0])\n",
    "\n",
    "# Filter: only Dict, CountingBloomFilter and CountMinSketch\n",
    "results = results[results[\"bloom-filter\"].isin([\"Dict\", \"CountingBloomFilter\", \"CountMinSketch\"])]\n",
    "best_results = best_results[best_results[\"bloom-filter\"].isin([\"Dict\", \"CountingBloomFilter\", \"CountMinSketch\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "\n",
    "for dset_name, dset_df in results.groupby(\"dataset\"):\n",
    "    best_model = best_results[best_results[\"dataset\"] == dset_name].iloc[0]\n",
    "    # print(f\"*** Dataset: {dset_name} with metric: {best_model['metric']} and model size: {int(best_model['model_size'])}\")\n",
    "    bests = dset_df[dset_df[\"metric\"] >= best_model[\"metric\"] - metric_threshold]\n",
    "    bests[\"metric_improvement\"] = bests[\"metric\"]/ best_model[\"metric\"]\n",
    "    bests[\"model_size_improvement\"] = bests[\"model_size\"]/ best_model[\"model_size\"]\n",
    "    bests[\"best_metric\"]  = best_model[\"metric\"]\n",
    "    bests[\"best_model_size\"]  = best_model[\"model_size\"]\n",
    "    temp.append(bests)\n",
    "    \n",
    "results = pd.concat(temp, ignore_index=True)\n",
    "results.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results.loc[results.groupby(\"dataset\")[\"model_size_improvement\"].idxmin()]\n",
    "best_results[\"bloom-filter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_table = best_results.sort_values(by=[\"dataset\"])[[\"dataset\", \"config_name\", \"model_size_improvement\"]]\n",
    "\n",
    "best_results_table.rename(\n",
    "    columns={\n",
    "        \"dataset\": \"Dataset\",\n",
    "        \"config_name\": \"Bloom Filter Configuration\",\n",
    "        \"model_size_improvement\": \"Size Ratio\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "best_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_str = best_results_table.to_latex(\n",
    "    index=False,\n",
    "    escape=True,\n",
    "    caption=\"Best Bloom Filter configuration for each dataset\",\n",
    "    label=\"tab:best_bloom_filter_agg\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "write_latex_table(\"best_bloom_filter_agg.tex\", latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_table = best_results.sort_values(by=[\"dataset\"])[[\"dataset\", \"bloom-filter\", \"config_name\", \"model_size_improvement\"]]\n",
    "best_results_table.groupby(\"bloom-filter\")[\"model_size_improvement\"].agg([\"mean\", \"std\", \"count\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
